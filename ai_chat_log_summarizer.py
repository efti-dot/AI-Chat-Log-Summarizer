# -*- coding: utf-8 -*-
"""AI_Chat_Log_Summarizer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zXA330VrY2pWDmMiqnws_6nJyVnCnR-K
"""

def parseChatLog(filePath):
  ai_messages = []
  user_messages = []

  with open(filePath, 'r', encoding='utf-8') as a:
        for l in a:
            l = l.strip()
            if l.startswith("User:"):
                user_messages.append(l[len("User:"):].strip())
            elif l.startswith("AI:"):
                ai_messages.append(l[len("AI:"):].strip())

  return user_messages, ai_messages

def messageStatistics(user_messages, ai_messages):
    total_messages = len(user_messages) + len(ai_messages)
    user_count = len(user_messages)
    ai_count = len(ai_messages)

    print(f"Total messages: {total_messages}")
    print(f"User messages: {user_count}")
    print(f"AI messages: {ai_count}")


from sklearn.feature_extraction.text import TfidfVectorizer
def tfidf(user_messages, ai_messages, n=5):
    all_messages = user_messages + ai_messages
    vectorizer = TfidfVectorizer(stop_words='english')
    tfidf_matrix = vectorizer.fit_transform(all_messages)
    tfidf_scores = tfidf_matrix.sum(axis=0).A1
    words = vectorizer.get_feature_names_out()
    word_scores = dict(zip(words, tfidf_scores))
    top_keywords = sorted(word_scores.items(), key=lambda x: x[1], reverse=True)[:n]

    print("\nTop Keywords:")
    for word, score in top_keywords:
        print(f"{word} ,Score: {score:.3f}")

    return [word for word, _ in top_keywords]


def generateSummary(user_messages, ai_messages, keywords):
    total_messages = len(user_messages) + len(ai_messages)

    print("\nConversation Summary:")
    print(f"The conversation had {total_messages} exchanges.")
    print(f"Most common keywords: {','.join(keywords)}")

filePath = "/content/drive/MyDrive/Chat (AI & user)/chat.txt"
user, ai = parseChatLog(filePath)
print("User Messages:", user)
print("AI Messages:", ai)
print("\n")
messageStatistics(user, ai)
keywords = tfidf(user, ai)
generateSummary(user, ai, keywords)
